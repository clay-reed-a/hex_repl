Things to understand:
--------------------- 

###Bytes & binary

Why are there ones & zeros inside computers?  

###Number vs. representation of number 

In a way, Hex Codes are just numbers. 

Most of the time, we go around thinking "10" is the number 10, and that's just that.

If you have done any coding at all, you have probably at one time or another spent a good hour pulling your hair out over a misunderstanding that turned out to be as ridiculous as:

    if (10 === "10") {
    	console.log("Yup, that's the number 10!"); 
    } else {
    	console.log("That is, like, not the number 10. What is that?");
    }
 
You can look at any "10" & I can look at any "10", anytime, anywhere, and we'll both recognize it as the number 10. Now I'm going to tell you this is wrong. 

In reality, this is just like how we can look at a word like "beaded" & think of, say, a necklace, perhaps one of a lovely pastel purple, like the kind of purple seen inside a sea shell. It makes sense because some necklaces are beaded & some beads are purple, so a beaded necklace could be a purple necklace. But there is no purple & there is no necklace, there is only "beaded". 

The way a computer language interprets "10" is not as the number 10, but as a sequence of symbols: to wit, the symbol "1" followed by the symbol "0". There isn't even anything inherent to the symbols in "10" that make the concept of the number ten appear in our minds. 

How can it be 11110000, f0 & 240 are all the same number?  

###additive colors & light 

Rainbows. Prisms. Black as an absence of color. 
